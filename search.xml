<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>docker常用命令</title>
    <url>/1c41d072cac63725dbd48a1273b2fd97.html</url>
    <content><![CDATA[<h1 id="docker常用命令"><a href="#docker常用命令" class="headerlink" title="docker常用命令"></a>docker常用命令</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull tensorflow/serving #从仓库拉取镜像</span><br><span class="line">docker pull tensorflow/serving:latest-gpu #从仓库拉取GPU镜像</span><br><span class="line">docker pull tensorflow/serving:2.8.3-gpu #从仓库拉取GPU镜像</span><br><span class="line">docker run -it tensorflow/serving #进入到镜像中</span><br><span class="line">exit #退出镜像</span><br><span class="line">docker run tensorflow/serving #运行某个容器</span><br><span class="line">docker ps // 查看所有正在运行容器</span><br><span class="line">docker stop containerId // containerId 是容器的ID</span><br><span class="line"></span><br><span class="line">docker ps -a // 查看所有容器</span><br><span class="line">docker ps -a -q // 查看所有容器ID</span><br><span class="line"></span><br><span class="line">docker stop $(docker ps -a -q) //  stop停止所有容器</span><br><span class="line">docker rm $(docker ps -a -q) //   remove删除所有容器</span><br><span class="line">docker rm/rmi #删除容器/镜像</span><br><span class="line">docker cp local_files containerId:docker_files #本地文件复制到docker</span><br></pre></td></tr></table></figure>

<h1 id="tf-serving部署"><a href="#tf-serving部署" class="headerlink" title="tf-serving部署"></a>tf-serving部署</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-p: 指定主机到docker容器的端口映射</span><br><span class="line">--mount: 表示要进行挂载,其中</span><br><span class="line">	type=bind: 是选择挂载模式，</span><br><span class="line">	source: 要部署模型的存储路径，也就是挂载的源（必须是绝对路径），</span><br><span class="line">	target: 要挂载的目标位置，模型挂载到docker容器中的位置，也就是docker容器中的目录（放在集装箱的哪里）</span><br><span class="line">-t: 指定的是挂载到哪个容器</span><br><span class="line">-e: 环境变量 </span><br><span class="line">	MODEL_NAME: 必须与target指定路径的最后一个文件夹名称相同</span><br><span class="line">--per_process_gpu_memory_fraction: 运行时所需的GPU显存资源最大比率的值设定</span><br><span class="line"></span><br><span class="line">-v:</span><br><span class="line">	path1:path2 分别指模型在机器种储存的路径（必须是绝对路径），模型在容器中储存的路径（放在集装箱的哪里）</span><br></pre></td></tr></table></figure>




<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -p 8500:8500 \</span><br><span class="line">    --mount type=bind,source=/Users/coreyzhong/workspace/tensorflow/saved_model/,target=/models/test-model \</span><br><span class="line">    -t tensorflow/serving:1.15.0 \</span><br><span class="line">    -e MODEL_NAME=test-model --model_base_path=/models/test-model/ &amp;</span><br></pre></td></tr></table></figure>





<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">model_path=&quot;/Users/havorld/jupyter/model_save/&quot;</span><br><span class="line">docker run -t --rm -p 8500:8500 -p 8501:8501 \</span><br><span class="line">  -v &quot;$model_path/din:/models/tf_saved_models&quot; \</span><br><span class="line">  -e MODEL_NAME=tf_saved_models \</span><br><span class="line">  tensorflow/serving &amp;</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">查看TensorFlow-Serving状态： curl http://localhost:8501/v1/models/$&#123;model_name&#125;</span><br><span class="line">查看TensorFlow-Serving模型信息： curl http://localhost:8501/v1/models/$&#123;model_name&#125;/metadata</span><br><span class="line">查看模型信息: saved_model_cli show --dir=&#x27;./$&#123;model_path&#125;/20220422104620&#x27; --all</span><br><span class="line">使用Http请求进行模型预测： </span><br><span class="line">curl -d &#x27;&#123;&quot;instances&quot;: [1,2,3,4,5]&#125;&#x27; -X POST http://localhost:8501/v1/models/$&#123;model_name&#125;:predict</span><br><span class="line">其中instances的value为模型输入Tensor的字符串形式，矩阵维度需要和Tensor对应。</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -t --rm -p 8501:8501 \</span><br><span class="line">    -v &quot;/home/Personas/havorld/tfserving/tf_saved_models:/models/tf_saved_models&quot; \</span><br><span class="line">    -e MODEL_NAME=tf_saved_models \</span><br><span class="line">    tensorflow/serving</span><br><span class="line"></span><br><span class="line">docker run -t --rm -p 8501:8501 \</span><br><span class="line">-v &quot;/Users/haopeng.meng/jupyter/tf_saved_models:/models/tf_saved_models&quot; \</span><br><span class="line">-e MODEL_NAME=tf_saved_models \</span><br><span class="line">tensorflow/serving</span><br><span class="line"></span><br><span class="line">cat /opt/logs/rec-feed-api/access.log | grep &quot;feed recommend-&gt; uid:55&quot; | grep &quot;id=34174686&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sudo docker run -t --rm -p 8501:8501 -p 8500:8500 \</span><br><span class="line">    -v &quot;/home/meng.haopeng/tfserving/tf_saved_models:/models/tf_saved_models&quot; \</span><br><span class="line">    -e MODEL_NAME=tf_saved_models \</span><br><span class="line">    tensorflow/serving</span><br><span class="line"></span><br><span class="line">docker run -p 8501:8501 -p 8500:8500 \</span><br><span class="line">	--mount type=bind,source=/Users/haopeng.meng/jupyter/tf_saved_models,target=/models/tf_saved_models \</span><br><span class="line">	-e MODEL_NAME=tf_saved_models \</span><br><span class="line">	-t tensorflow/serving</span><br><span class="line"></span><br><span class="line">docker run -p 8500:8500 \</span><br><span class="line">      --mount type=bind,source=./intent/,target=/models/intent_score \</span><br><span class="line">      -e MODEL_NAME=intent_score -t tensorflow/serving:1.10.0</span><br><span class="line"></span><br><span class="line">docker run -p 8501:8501 -p 8500:8500 --mount type=bind,source=/my/model/path/m,target=/models/m -e MODEL_NAME=m -t tensorflow/serving:2.1.0</span><br><span class="line"></span><br><span class="line">sudo docker run -t --rm -p 8501:8501 -p 8500:8500 \</span><br><span class="line">    -v &quot;/home/meng.haopeng/tfserving/tf_saved_models:/models/tf_saved_models&quot; \</span><br><span class="line">    -e MODEL_NAME=tf_saved_models \</span><br><span class="line">    tensorflow/serving</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">docker run -t -p 443:8500 -p 8500:8501 -v <span class="string">&quot;/data/lsj/dmp/SavedModel/:/models/&quot;</span> tensorflow/serving --model_config_file=/models/models.config --model_config_file_poll_wait_seconds=300</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">run use container</span></span><br><span class="line">docker run -t -p 8501:8500 --name=tf_serving_multi_version_01 -v &quot;/data/tf-model/models/:/models/&quot; tensorflow/serving --model_config_file=/models/models.config --model_config_file_poll_wait_seconds=300 --allow_version_labels_for_unavailable_models=true --enable_batching=true --batching_parameters_file=/models/batch.config</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tf-serving部署</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -t --rm -p 8501:8501 \</span><br><span class="line">-v &quot;/Users/haopeng.meng/jupyter/tf_saved_models:/models/tf_saved_models&quot; \</span><br><span class="line">-e MODEL_NAME=tf_saved_models \</span><br><span class="line">tensorflow/serving</span><br><span class="line"></span><br><span class="line">docker run -p 8501:8501 -p 8500:8500 \</span><br><span class="line">	--mount type=bind,source=/Users/haopeng.meng/jupyter/tf_saved_models,target=/models/tf_saved_models \</span><br><span class="line">	-e MODEL_NAME=tf_saved_models \</span><br><span class="line">	-t tensorflow/serving</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">sudo docker run -t --rm -p 8501:8501 -p 8500:8500 \</span><br><span class="line">    -v &quot;/home/meng.haopeng/tfserving/tf_saved_models:/models/tf_saved_models&quot; \</span><br><span class="line">    -e MODEL_NAME=tf_saved_models \</span><br><span class="line">    tensorflow/serving</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sudo docker run --name feed -t --rm -p 8700:8500 -p 8701:8501 \</span><br><span class="line">    -v &quot;/home/meng.haopeng/tfserving/tf_saved_models:/models/tf_saved_models&quot; \</span><br><span class="line">    -e MODEL_NAME=tf_saved_models \</span><br><span class="line">    tensorflow/serving</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run --name feed -t --rm -p 8701:8501 -p 8700:8500 \</span><br><span class="line">	--mount type=bind,source=/home/Personas/havorld/tfserving/model_save,target=/models/model_save \</span><br><span class="line">	-e MODEL_NAME=model_save \</span><br><span class="line">	-t tensorflow/serving:latest-gpu </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run --name feed -t --rm -p 8700:8500 -p 8701:8501 \</span><br><span class="line">	--mount type=bind,source=/Users/haopeng.meng/Desktop/recommend/rec-alg-feed/model_save/din/serving/,target=/models/serving \</span><br><span class="line">	-e MODEL_NAME=serving \</span><br><span class="line">	-t tensorflow/serving</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">docker run --name feed -t --rm -p 8700:8500 -p 8701:8501 \</span><br><span class="line">        --mount type=bind,source=/Users/haopeng.meng/Desktop/recommend/serving/din/,target=/models/serving \</span><br><span class="line">        -e MODEL_NAME=serving \</span><br><span class="line">        -t tensorflow/serving</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>tfserving</tag>
      </tags>
  </entry>
  <entry>
    <title>git常用命令</title>
    <url>/cuidAoCCa2Y1y3mSfmdcomPoP.html</url>
    <content><![CDATA[<h2 id="git常用命令"><a href="#git常用命令" class="headerlink" title="git常用命令"></a>git常用命令</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/username/project.github.io.git #拉取代码(master/main)</span><br><span class="line">git clone -b _dev https://github.com/username/project.github.io.git  #拉取分支(非master或main分支)</span><br><span class="line">git checkout --track origin/_remote  #获取指定的远程分支到本地</span><br><span class="line"></span><br><span class="line">git branch #查看本地分支</span><br><span class="line">git branch -a #查看远程分支</span><br><span class="line">git branch -vv#查看分支的绑定信息</span><br><span class="line"></span><br><span class="line">git branch _local #创建本地分支</span><br><span class="line">git branch -d _local #删除本地分支(当前分支不能停留在要删除的分支上)</span><br><span class="line">git checkout _local #切换到本地分支</span><br><span class="line">git checkout -b _local # 创建并切换到本地创建的分支</span><br><span class="line"></span><br><span class="line">git push --set-upstream origin _remote #创建远程分支</span><br><span class="line">git branch -r -d origin/_remote  #删除远程分支(记得push一下 git push origin _remote)</span><br><span class="line">git checkout -b _local origin/_remote #创建本地分支绑定远程分支</span><br><span class="line"></span><br><span class="line">git status #查看修改过代码的类</span><br><span class="line">git diff #查看修改的代码</span><br><span class="line"></span><br><span class="line">git add src/main/java/com/so/alg/RecommendServiceImpl.java #添加修改的代码</span><br><span class="line">git commit -m &quot;recommend feed modified&quot; #给修改的代码添加注释</span><br><span class="line">git pull origin _remote #从远程更新变动的代码</span><br><span class="line">git push origin _local:_remote #提交</span><br><span class="line"></span><br><span class="line">git merge _remote #合并分支到master上(需要先切换到master分支上,在执行合并)</span><br><span class="line"></span><br><span class="line">git tag -a 2020071801 -m &#x27;v2.0部署&#x27; #添加tag</span><br><span class="line">git show 2020071801 #展示tag</span><br><span class="line">git push --tags  #提交tag</span><br></pre></td></tr></table></figure>



<h2 id="git配置SSH公钥和私钥"><a href="#git配置SSH公钥和私钥" class="headerlink" title="git配置SSH公钥和私钥"></a>git配置SSH公钥和私钥</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1.生成公钥和私钥(邮箱为github注册邮箱)</span></span><br><span class="line">ssh-keygen -t rsa -C &quot;xxxxxx@gmail.com&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2.设置公钥私钥key的保存位置(可以直接确认则保存在默认位置)</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/Users/username/.ssh/id_rsa):</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3.输入、重复输入密钥盐值</span></span><br><span class="line">Enter passphrase (empty for no passphrase):</span><br><span class="line">Enter same passphrase again:</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4.复制打印的公钥内容，并在github-&gt;Settings-&gt;SSH and GPG keys-&gt;New SSH Key中设置(title随意起)</span></span><br><span class="line">cat .ssh\id_rsa.pub</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5.查看密钥是否配置成功(会提示输入盐值)</span></span><br><span class="line">ssh -T git@github.com</span><br><span class="line">Enter passphrase for key &#x27;/Users/username/.ssh/id_rsa&#x27;:</span><br><span class="line">Hi hicode360! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">6.配置全局git信息</span></span><br><span class="line">git config --global user.name &quot;username&quot; # github用户名</span><br><span class="line">git config --global user.email  &quot;xxxxxx@gmail.com&quot; #github注册邮箱</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title>python中的数据类型</title>
    <url>/cuidE3N3yPZPwlwuDHdu4UrZd.html</url>
    <content><![CDATA[<h1 id="Python中的数据类型"><a href="#Python中的数据类型" class="headerlink" title="Python中的数据类型"></a>Python中的数据类型</h1><h2 id="可变数据类型"><a href="#可变数据类型" class="headerlink" title="可变数据类型"></a>可变数据类型</h2><p>对变量的值进行修改时，变量对应的内存地址不变，对应的值发生了改变，这种数据类型就称为可变数据类型。</p>
<h2 id="不可变数据类型"><a href="#不可变数据类型" class="headerlink" title="不可变数据类型"></a>不可变数据类型</h2><p>对变量的进行修改时，变量对应的内存地址发生了改变(变量指向了新的内存)，从而修改了变量的值，而变量对应的原内存的值并没有被改变，这种数据类型就称为可变数据类型。</p>
<p>也就是：不可变数据类型更改后地址发生改变，可变数据类型更改地址不发生改变</p>
<h2 id="常用数据类型"><a href="#常用数据类型" class="headerlink" title="常用数据类型"></a>常用数据类型</h2><table>
<thead>
<tr>
<th>数据类型</th>
<th>是否是可变数据类型</th>
<th>是否有序</th>
</tr>
</thead>
<tbody><tr>
<td>None (空)</td>
<td>不可变</td>
<td>-</td>
</tr>
<tr>
<td>int (整数)</td>
<td>不可变</td>
<td>-</td>
</tr>
<tr>
<td>float (浮点)</td>
<td>不可变</td>
<td>-</td>
</tr>
<tr>
<td>bool (布尔)</td>
<td>不可变</td>
<td>-</td>
</tr>
<tr>
<td>str (字符串)</td>
<td>不可变</td>
<td>-</td>
</tr>
<tr>
<td>tuple (元组)</td>
<td>不可变</td>
<td>序列类型，有序</td>
</tr>
<tr>
<td>list (列表)</td>
<td>可变</td>
<td>序列类型，有序</td>
</tr>
<tr>
<td>set (集合)</td>
<td>可变</td>
<td>序列类型，无序，不可重复</td>
</tr>
<tr>
<td>dict (字典)</td>
<td>可变</td>
<td>映射类型，v3.6及以后无有序, 前面版本无序</td>
</tr>
</tbody></table>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><table>
<thead>
<tr>
<th>数据类型</th>
<th>是否是可变数据类型</th>
<th>是否有序</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>bytes</td>
<td>不可变</td>
<td>-</td>
<td>定义字节：b’hello’,bytes(5)</td>
</tr>
<tr>
<td>bytearray</td>
<td>可变</td>
<td>-</td>
<td>定义字节数组：bytearray(b’hello’), bytearray(10)</td>
</tr>
<tr>
<td>complex (复数)</td>
<td>不可变</td>
<td>-</td>
<td>由一个实数和一个虚数组合构成，如：4+3j</td>
</tr>
<tr>
<td>frozenset (冻结的set)</td>
<td>不可变</td>
<td>无序</td>
<td>冻结的set初始化后不能再添加或删除元素</td>
</tr>
<tr>
<td>array (数组)</td>
<td>可变</td>
<td>有序</td>
<td>数组中的元素必须是同一类型</td>
</tr>
<tr>
<td>OrderedDict</td>
<td>可变</td>
<td>有序</td>
<td>key有序，setdefault取值key不存在也不报错</td>
</tr>
<tr>
<td>defaultdict</td>
<td>可变</td>
<td>有序</td>
<td>取值时Key不存在也不会抛出KeyError异常</td>
</tr>
<tr>
<td>deque</td>
<td>可变</td>
<td>有序</td>
<td>高效插入和删除的<strong>双向队列列表</strong></td>
</tr>
</tbody></table>
<h2 id="常见数据类型的操作和转换"><a href="#常见数据类型的操作和转换" class="headerlink" title="常见数据类型的操作和转换"></a>常见数据类型的操作和转换</h2><h3 id="list列表"><a href="#list列表" class="headerlink" title="list列表[ ]"></a>list列表[ ]</h3><p>list是**&#x3D;&#x3D;可变&#x3D;&#x3D;<strong>、</strong>&#x3D;&#x3D;可重复&#x3D;&#x3D;<strong>的</strong>&#x3D;&#x3D;有序&#x3D;&#x3D;**列表，里面的元素的数据类型也可以不同(也可以是另一个list)。list可根据索引号取其中的数据。</p>
<h4 id="list的生成"><a href="#list的生成" class="headerlink" title="list的生成"></a>list的生成</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list1 = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list1: &quot;</span>, <span class="built_in">list</span>(list1)) <span class="comment"># 输出： list1:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span></span><br><span class="line">list2 = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list2: &quot;</span>, <span class="built_in">list</span>(list2))</span><br><span class="line">list3 = [i*i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>) <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list3: &quot;</span>, <span class="built_in">list</span>(list3))</span><br><span class="line">list4 = (<span class="built_in">str</span>(i) + j <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="string">&quot;xyz&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list4: &quot;</span>, <span class="built_in">list</span>(list4))</span><br></pre></td></tr></table></figure>
<h4 id="list元素反转、排序和次数统计"><a href="#list元素反转、排序和次数统计" class="headerlink" title="list元素反转、排序和次数统计"></a>list元素反转、排序和次数统计</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list1 = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line"></span><br><span class="line">list1.reverse()  <span class="comment"># 元素顺序反转</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list reverse: &quot;</span>, list1)</span><br><span class="line">list1.sort(reverse=<span class="literal">False</span>)  <span class="comment"># 排序</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list sort: &quot;</span>, list1)</span><br><span class="line">list1 = <span class="built_in">sorted</span>(list1, reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list sort: &quot;</span>, list1)</span><br><span class="line">times = list1.count(<span class="number">5</span>)  <span class="comment"># 查看list中的元素出现的次数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;times: &quot;</span>, times)</span><br></pre></td></tr></table></figure>
<h4 id="list元素的添加、删除和取值"><a href="#list元素的添加、删除和取值" class="headerlink" title="list元素的添加、删除和取值"></a>list元素的添加、删除和取值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list1.append(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;append value: &quot;</span>, list1)  <span class="comment"># 添加元素</span></span><br><span class="line">list1.insert(<span class="number">1</span>, <span class="number">10</span>)  <span class="comment"># 在指定位置添加元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;insert value: &quot;</span>, list1)</span><br><span class="line">list1.remove(<span class="number">10</span>)  <span class="comment"># 删除指定value元素(第一个匹配的元素)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;remove value: &quot;</span>, list1)</span><br><span class="line">value = list1.pop(<span class="number">12</span>)  <span class="comment"># 删除指定index的元素并返回删除的值</span></span><br><span class="line">list1.pop()  <span class="comment"># 不指定index时默认删除最后一个元素</span></span><br><span class="line">list1.pop(-<span class="number">2</span>)  <span class="comment"># 删除倒数第二个元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;remove index: &quot;</span>, list1)</span><br><span class="line"></span><br><span class="line">index_value = list1.index(<span class="number">3</span>)  <span class="comment"># 查找第一个value为100的index值，如果不存在报TypeError异常</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;index_value: &quot;</span>, index_value)</span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line">index_value = list1.index(<span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>)  <span class="comment"># 指定范围，从第7(包括)个到第9(不包括)个元素之间查找value为5的index</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;index_value: &quot;</span>, index_value)</span><br></pre></td></tr></table></figure>
<h4 id="list添加多个元素、list的合并"><a href="#list添加多个元素、list的合并" class="headerlink" title="list添加多个元素、list的合并"></a>list添加多个元素、list的合并</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list2 = [<span class="number">100</span>, <span class="number">101</span>, <span class="number">102</span>]</span><br><span class="line"><span class="comment"># list1 = list1 + list2</span></span><br><span class="line">list1.extend(list2)</span><br><span class="line"><span class="built_in">print</span>(list1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span> * <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h4 id="list的遍历"><a href="#list的遍历" class="headerlink" title="list的遍历"></a>list的遍历</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> list1:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;value: %i&quot;</span> % value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(list1)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;index: %i, value: %i&quot;</span> % (index, list1[index]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> index, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(list1):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;index: %i, value: %i&quot;</span> % (index, value))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> index, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(list1, <span class="number">100</span>):  <span class="comment"># index从100开始</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;index: %i, value: %i&quot;</span> % (index, value))</span><br></pre></td></tr></table></figure>

<h4 id="list中使用切片-slice-取值"><a href="#list中使用切片-slice-取值" class="headerlink" title="list中使用切片(slice)取值"></a>list中使用切片(slice)取值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">elements = list1[<span class="number">0</span>:<span class="number">3</span>]  <span class="comment"># 取第0到3条元素(包括头不包括尾)</span></span><br><span class="line"><span class="comment"># elements = list1[:3]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;slice elements: &quot;</span>, elements)</span><br><span class="line">elements = list1[<span class="number">1</span>:]  <span class="comment"># 取第1到最后一个元素(包括头也包括尾)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;slice elements: &quot;</span>, elements)</span><br><span class="line">elements = list1[-<span class="number">2</span>]  <span class="comment"># 取倒数第二条</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;slice elements: &quot;</span>, elements)</span><br><span class="line">elements = list1[<span class="number">4</span>:-<span class="number">2</span>]  <span class="comment"># 取第四条到倒数第二条(包括头不包括尾)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;slice elements: &quot;</span>, elements)</span><br><span class="line">elements = list1[<span class="number">0</span>:<span class="number">6</span>:<span class="number">2</span>]  <span class="comment"># 取第0条到第6条中每2个取一个</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;slice elements: &quot;</span>, elements)</span><br><span class="line">elements = list1[:]  <span class="comment"># 取所有元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;slice elements: &quot;</span>, elements)</span><br></pre></td></tr></table></figure>
<p><strong>&#x3D;&#x3D;列表、元组和字符串&#x3D;&#x3D;都可以使用切片进行操作</strong></p>
<h4 id="list的深copy和浅copy"><a href="#list的深copy和浅copy" class="headerlink" title="list的深copy和浅copy"></a>list的深copy和浅copy</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 浅拷贝只拷贝了引用，没有拷贝内容</span></span><br><span class="line">list2 = list1</span><br><span class="line">list2[<span class="number">1</span>] = <span class="number">1000</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list1: &quot;</span>, list1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list2: &quot;</span>, list1)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(list1), <span class="built_in">id</span>(list2))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 深拷贝是对于一个对象所有层次的拷贝(递归拷贝)</span></span><br><span class="line">list3 = list1.copy()</span><br><span class="line"><span class="comment"># import copy</span></span><br><span class="line"><span class="comment"># list3 = copy.copy(list1)</span></span><br><span class="line"><span class="comment"># list3 = copy.deepcopy(list1)</span></span><br><span class="line">list1[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list1: &quot;</span>, list1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;list3: &quot;</span>, list3)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(list1), <span class="built_in">id</span>(list3))</span><br></pre></td></tr></table></figure>

<h3 id="set集合"><a href="#set集合" class="headerlink" title="set集合{ }"></a>set集合{ }</h3><p>set是**&#x3D;&#x3D;可变&#x3D;&#x3D;**、&#x3D;&#x3D;<strong>不可重复</strong>&#x3D;&#x3D;的&#x3D;&#x3D;<strong>无序</strong>&#x3D;&#x3D;列表。 &#x3D;&#x3D;<strong>set中不可以放入可变对象</strong>&#x3D;&#x3D;，因为无法判断两个可变对象是否相等而去重。</p>
<h4 id="set的定义"><a href="#set的定义" class="headerlink" title="set的定义"></a>set的定义</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">set0 = &#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>&#125;  <span class="comment"># 直接定义set集合</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set0: &quot;</span>, set0)  <span class="comment"># 输出 set0:  &#123;0,1, 2, 3, 4, 5, 6&#125;</span></span><br><span class="line"></span><br><span class="line">set1 = <span class="built_in">set</span>([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])  <span class="comment"># 通过list定义set</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set1: &quot;</span>, set1)</span><br><span class="line"></span><br><span class="line">set2 = <span class="built_in">set</span>((<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>))  <span class="comment"># 通过tuple定义set</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set2: &quot;</span>, set2)</span><br><span class="line"></span><br><span class="line">set3 = <span class="built_in">set</span>(&#123;<span class="string">&quot;x&quot;</span>: <span class="number">2</span>, <span class="number">10</span>: <span class="string">&quot;b&quot;</span>&#125;)  <span class="comment"># 通过dict定义set</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set3: &quot;</span>, set3)  <span class="comment"># 输出 set3:  &#123;10, &#x27;x&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line">my_list = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">set4 = <span class="built_in">set</span>(my_list)  <span class="comment"># set中不可以放入可变对象,然而为何放入list却不报错?</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set4: &quot;</span>, set4)  <span class="comment"># 输出 set4:  &#123;0, 1, 2, 3, 4, 5, 6&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 由下面操作可以得出结论,set是先把list做遍历得到不可变的int对象类型后再放入set中</span></span><br><span class="line">my_list[<span class="number">0</span>] = <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set4 with my_list changed: &quot;</span>, set4)  <span class="comment"># 输出 &#123;0, 1, 2, 3, 4, 5, 6&#125;</span></span><br><span class="line"></span><br><span class="line">my_list.append([<span class="number">10</span>, <span class="number">20</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;my_list: &quot;</span>, my_list)</span><br><span class="line">set5 = <span class="built_in">set</span>(my_list)  <span class="comment"># 在list再放入list,此时将报错</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set5: &quot;</span>, set5)</span><br></pre></td></tr></table></figure>

<h4 id="set元素的添加、删除和取值"><a href="#set元素的添加、删除和取值" class="headerlink" title="set元素的添加、删除和取值"></a>set元素的添加、删除和取值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">set0 = &#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set0: &quot;</span>, set0)</span><br><span class="line">set0.add(<span class="string">&quot;cn&quot;</span>)  <span class="comment"># 添加单个元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set0: &quot;</span>, set0)</span><br><span class="line"></span><br><span class="line">set0.update([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>])  <span class="comment"># 添加多个元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set0: &quot;</span>, set0)</span><br><span class="line"></span><br><span class="line">set0.add((<span class="string">&quot;com&quot;</span>, <span class="string">&quot;cn&quot;</span>))  <span class="comment"># 添加元组(元组是不可变数据类型)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set0: &quot;</span>, set0)</span><br><span class="line"><span class="comment"># set0.add([10, 20])  # 添加list报错,不能添加可变的数据类型(不能添加,但可以使用list创建set)</span></span><br><span class="line"><span class="comment"># set0.add(&#123;10, 20&#125;)  # 添加set报错,(可是使用不可变的frozenset添加:set0.add(frozenset(&#123;10, 20&#125;)))</span></span><br><span class="line"><span class="comment"># set0.add(&#123;&quot;x&quot;: 2, 10: &quot;b&quot;&#125;)  # 添加dict报错,不能添加可变的数据类型(不能添加,但可以使用dict创建set)</span></span><br><span class="line"></span><br><span class="line">set0.remove(<span class="string">&quot;cn&quot;</span>)  <span class="comment"># 根据值删除元素(set不能根据索引删除)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;set0: &quot;</span>, set0)</span><br></pre></td></tr></table></figure>

<h4 id="set取并集和交集"><a href="#set取并集和交集" class="headerlink" title="set取并集和交集"></a>set取并集和交集</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">set1 = &#123;<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">100</span>&#125;</span><br><span class="line">my_set = set0 | set1  <span class="comment"># 取并集</span></span><br><span class="line"><span class="built_in">print</span>(my_set)</span><br><span class="line">my_set = set0 &amp; set1  <span class="comment"># 取交集</span></span><br><span class="line"><span class="built_in">print</span>(my_set)</span><br></pre></td></tr></table></figure>

<h4 id="set遍历"><a href="#set遍历" class="headerlink" title="set遍历"></a>set遍历</h4><p>注：set的遍历同list</p>
<h3 id="dict字典"><a href="#dict字典" class="headerlink" title="dict字典{ }"></a>dict字典{ }</h3><p>dict是**&#x3D;&#x3D;无序&#x3D;&#x3D;<strong>，key&#x3D;&#x3D;<strong>不可重复</strong>&#x3D;&#x3D;、</strong>&#x3D;&#x3D;不可变&#x3D;&#x3D;**内容以key-value键值对形式存在的映射</p>
<p><strong>dict中的key只能是不可变对象且唯一</strong>, 一个key对应一个value，多次对一个key设置value，后面的值会把前面的冲掉。</p>
<blockquote>
<p>dict一般用在需要高速查找的很多地方。dict的key必须是不可变对象，这是因为dict根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。这种通过key计算位置的算法称为哈希算法（Hash）。要保证hash的正确性，作为key的对象就不能变。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list、set是可变的，所以就不能作为key。</p>
</blockquote>
<h4 id="dict的创建和增删改查"><a href="#dict的创建和增删改查" class="headerlink" title="dict的创建和增删改查"></a>dict的创建和增删改查</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dict1 = &#123;<span class="string">&quot;addr&quot;</span>: <span class="string">&quot;北京&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">18</span>, <span class="string">&quot;gender&quot;</span>: <span class="string">&quot;女&quot;</span>&#125;</span><br><span class="line">dict1[<span class="string">&quot;height&quot;</span>] = <span class="number">1.77</span>  <span class="comment"># 添加元素</span></span><br><span class="line">dict1.pop(<span class="string">&quot;age&quot;</span>)  <span class="comment"># 删除元素输出</span></span><br><span class="line">item_del = dict1.popitem()  <span class="comment"># 产出dict中的最后一个item并返回</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;item_del: &quot;</span>, item_del)</span><br><span class="line">dict1[<span class="string">&quot;addr&quot;</span>] = <span class="string">&quot;深圳&quot;</span>  <span class="comment"># 修改元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dict1: &quot;</span>, dict1)</span><br><span class="line"></span><br><span class="line">keys = dict1.keys()  <span class="comment"># 获取dict的所有key</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;keys: &quot;</span>, keys)  <span class="comment"># dict_keys([&#x27;add&#x27;, &#x27;height&#x27;])</span></span><br><span class="line">addr = dict1.get(<span class="string">&quot;addr&quot;</span>)  <span class="comment"># 根据key获取value,若key不存在报异常(defaultdict字典不报异常)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;addr: &quot;</span>, addr)</span><br><span class="line">addr = dict1.setdefault(<span class="string">&quot;addr&quot;</span>)  <span class="comment"># 根据key获取value,若key不存返回None,也可设置默认返回值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;addr: &quot;</span>, addr)</span><br><span class="line">name = dict1.get(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;unknow&quot;</span>)  <span class="comment"># 根据key获取value,若key不存返回默认值&#x27;unknow&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;name: &quot;</span>, name)</span><br></pre></td></tr></table></figure>

<h4 id="dict的遍历"><a href="#dict的遍历" class="headerlink" title="dict的遍历"></a>dict的遍历</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dict的遍历</span></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> dict1:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;key: %s, value: %s&quot;</span> % (key, dict1[key]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> dict1.values():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;value: &quot;</span>, value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;*&quot;</span> * <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> dict1.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;key: %s, value: %s&quot;</span> % (key, value))</span><br></pre></td></tr></table></figure>

<h4 id="dict的合并"><a href="#dict的合并" class="headerlink" title="dict的合并"></a>dict的合并</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dict2 = &#123;<span class="string">&quot;mobel&quot;</span>: <span class="number">15888888888</span>, <span class="string">&quot;postal_code&quot;</span>: <span class="number">10000</span>&#125;  <span class="comment"># 合并两个dict</span></span><br><span class="line">dict1.update(dict2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dict1: &quot;</span>, dict1)</span><br></pre></td></tr></table></figure>

<h4 id="dict和list的异同"><a href="#dict和list的异同" class="headerlink" title="dict和list的异同"></a>dict和list的异同</h4><blockquote>
<p><strong>list</strong>查找和插入的时间随着元素的增加而增加；<br>占用空间小，浪费内存很少</p>
</blockquote>
<blockquote>
<p><strong>dict</strong>查找和插入的速度极快，不会随着key的增加而变慢；<br>需要占用大量的内存，内存浪费多。<br>所以，dict是用空间来换取时间的一种方法。</p>
</blockquote>
<h4 id="dict的排序"><a href="#dict的排序" class="headerlink" title="dict的排序"></a>dict的排序</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dict排序</span></span><br><span class="line">dict3 = &#123;<span class="string">&#x27;sh&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;hz&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;tj&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;bj&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;gz&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;sz&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;wh&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认排序，并仅返回key</span></span><br><span class="line">key_rank1 = <span class="built_in">sorted</span>(dict3.keys(), reverse=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;key_rank1: &quot;</span>, key_rank1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认排序(以key来排序)，并返回key和value</span></span><br><span class="line">dict_key_rank1 = <span class="built_in">sorted</span>(dict3.items(), reverse=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dict_key_rank1: &quot;</span>, <span class="built_in">dict</span>(dict_key_rank1))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以key排序</span></span><br><span class="line">dict_key_rank2 = <span class="built_in">sorted</span>(dict3.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">0</span>], reverse=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dict_key_rank2: &quot;</span>, <span class="built_in">dict</span>(dict_key_rank2))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以value排序</span></span><br><span class="line">dict_value_rank1 = <span class="built_in">sorted</span>(dict3.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dict_value_rank1: &quot;</span>, <span class="built_in">dict</span>(dict_value_rank1))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以value排序</span></span><br><span class="line">dict4 = &#123;<span class="string">&#x27;上海&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;杭州&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;天津&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;北京&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;广州&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;深圳&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;武汉&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">dict_value_rank2 = <span class="built_in">sorted</span>(dict4.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;dict_value_rank2: &quot;</span>, <span class="built_in">dict</span>(dict_value_rank2))</span><br></pre></td></tr></table></figure>



<h3 id="tuple元组"><a href="#tuple元组" class="headerlink" title="tuple元组( )"></a>tuple元组( )</h3><p>tuple是**&#x3D;&#x3D;不可变&#x3D;&#x3D;<strong>、</strong>&#x3D;&#x3D;有序&#x3D;&#x3D;**的列表，所以一般在定义tuple时就进行初始化赋值。</p>
<p>注意：</p>
<ul>
<li><p>在定义只有一个元素的tuple时其元素后面要加逗号</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tuple0 = ()  <span class="comment"># 创建空元祖</span></span><br><span class="line">tuple0 = (<span class="number">1</span>)  <span class="comment"># 不是tuple，会当成括号处理</span></span><br><span class="line">tuple0 = (<span class="number">1</span>,)  <span class="comment"># 正确的tuple</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>tuple虽然不可变但tuple中的元素对象却是可变的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">my_list = [<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>]</span><br><span class="line">tuple1 = (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, my_list)  <span class="comment"># tuple包含list,list变化时,tuple1也就跟着变化</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;tuple1: &quot;</span>, tuple1)  <span class="comment"># tuple1:  (&#x27;a&#x27;, &#x27;b&#x27;, [&#x27;x&#x27;, &#x27;y&#x27;])</span></span><br><span class="line">my_list.append(<span class="string">&quot;z&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;tuple1 with my_list changed: &quot;</span>, tuple1)  <span class="comment"># tuple1变为(&#x27;a&#x27;, &#x27;b&#x27;, [&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="tuple的创建"><a href="#tuple的创建" class="headerlink" title="tuple的创建"></a>tuple的创建</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tuple2 = (<span class="number">1</span>, <span class="string">&quot;good&quot;</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">&quot;good&quot;</span>, <span class="literal">True</span>)  <span class="comment"># 创建元组,里面的元素类型可以不同</span></span><br><span class="line">tuple3 = (<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, *tuple2, <span class="number">4</span>, <span class="number">5</span>)  <span class="comment"># 元组引用另一个数组中的所有元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;tuple3: &quot;</span>, tuple3)</span><br></pre></td></tr></table></figure>

<h4 id="tuple中元素的增删改查"><a href="#tuple中元素的增删改查" class="headerlink" title="tuple中元素的增删改查"></a>tuple中元素的增删改查</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">element = tuple2[<span class="number">4</span>]  <span class="comment"># 根据索引获取元组中的元素</span></span><br><span class="line">element = tuple2[-<span class="number">2</span>]  <span class="comment"># 使用索引获取元组中的元素</span></span><br><span class="line">index = tuple2.index(<span class="string">&quot;good&quot;</span>)  <span class="comment"># 获取第一个匹配给定值的index值</span></span><br><span class="line"><span class="keyword">del</span> tuple2  <span class="comment"># 删除元组</span></span><br><span class="line"><span class="comment"># tuple2[4] = &quot;well&quot; # 修改元组的元素,报错</span></span><br><span class="line"></span><br><span class="line">tuple4 = (<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="number">4</span>, <span class="number">5</span>, [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;tuple4: &quot;</span>, tuple4)</span><br><span class="line"><span class="comment"># tuple4[-1] = [10, 20, 30] #报错</span></span><br><span class="line">tuple4[-<span class="number">1</span>][<span class="number">0</span>] = <span class="number">100</span>  <span class="comment"># 可以通过修改元组中的list,从而改变元组</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;tuple4: &quot;</span>, tuple4) <span class="comment"># tuple4:  (&#x27;a&#x27;, &#x27;b&#x27;, 4, 5, [100, 7, 8])</span></span><br></pre></td></tr></table></figure>

<h4 id="tuple的遍历"><a href="#tuple的遍历" class="headerlink" title="tuple的遍历"></a>tuple的遍历</h4><p>注：tuple的遍历同list</p>
]]></content>
      <categories>
        <category>工程与实战</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习导论</title>
    <url>/cuiddkt9gfQ2CHs2DJB4zDlSF.html</url>
    <content><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>在传统的编程范式中，我们输入数据和规则，通过计算机得到答案。而机器学习（Machine Learning）则不同，我们向计算机输入数据和答案（即最终的结果），让计算机自己去发现其中的学习模型、发现规律，从而构建能够进行预测的数学模型。简而言之，<strong>机器学习是一门研究如何让计算机从数据中自动获取规律，并利用这些规律来预测未知、辅助决策的科学。</strong></p>
<p>机器学习是一门交叉学科，根据不同的视角可以被划分为多种范式，如： </p>
<p>从<strong>统计推断的哲学思想</strong>划分，机器学习模型可以划分为：<strong>频率学派与贝叶斯学派</strong>。前者认为模型的参数是固定但未知的“常数”，学习的过程就是通过优化方法寻找这个最优值；而后者则认为参数本身服从某种分布，学习的过程是在观察数据后，对先验信念进行更新。</p>
<p>若从<strong>建模的最终目标</strong>划分，算法模型又可分为<strong>判别式模型与生成式模型</strong>。判别式模型关注的是寻找不同类别之间的决策边界，直接学习如何划分数据；而生成式模型则试图理解数据本身的产生过程，通过学习联合分布来间接进行预测。</p>
<h1 id="按统计推断划分"><a href="#按统计推断划分" class="headerlink" title="按统计推断划分"></a>按统计推断划分</h1><h2 id="频率学派"><a href="#频率学派" class="headerlink" title="频率学派"></a>频率学派</h2><h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>频率派（Frequentist）将概率解释为事件在长期重复试验中发生的频率。在这一框架下，模型参数 $ \theta $ 被视为一个确定的未知常量，虽然我们不知道它的具体值，但它本身并不具有随机性。我们只能通过观测数据来估计这个常量的值。</p>
<h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h3><p>给定观测数据集 $ X $，所有样本的联合概率为：</p>
<p>$$p(X|\theta) = \prod_{i=1}^N p(x_i|\theta)$$</p>
<p>这个联合概率被称为<strong>似然函数</strong>（Likelihood Function），它衡量了在特定参数 $ \theta $ 下观测到当前数据的可能性。频率派的估计方法就是寻找能使似然函数最大化的参数值，即<strong>最大似然估计</strong>（Maximum Likelihood Estimation, MLE）：</p>
<p>$$\theta_{MLE} = \arg\max_{\theta} p(X|\theta) = \arg\max_{\theta} \sum_{i=1}^N \log p(x_i|\theta)$$</p>
<p>由于对数函数是单调递增的，且能将连乘转化为连加便于计算，实际中通常使用对数似然。</p>
<h3 id="频率派与机器学习"><a href="#频率派与机器学习" class="headerlink" title="频率派与机器学习"></a>频率派与机器学习</h3><p>频率派的思想深刻影响了<strong>统计机器学习</strong>的发展。许多经典算法都可以从MLE的角度理解：</p>
<ul>
<li><strong>线性回归</strong>：假设误差服从高斯分布时，MLE等价于最小二乘法</li>
<li><strong>逻辑回归</strong>：直接对条件概率 $ p(y|x) $ 进行MLE估计</li>
<li><strong>支持向量机</strong>：可以看作是在特定损失函数下的频率派方法</li>
</ul>
<p>频率派方法的优势在于其理论简洁性、计算效率高，且在大样本条件下具有良好的渐近性质。然而，它也存在明显的局限性：无法融入先验知识，在小样本情况下容易过拟合，且只能给出点估计而非分布估计。</p>
<hr>
<h3 id="频率学派的参数估计"><a href="#频率学派的参数估计" class="headerlink" title="频率学派的参数估计"></a>频率学派的参数估计</h3><table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>全称</strong></th>
<th><strong>核心思想</strong></th>
<th><strong>适用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>MLE</strong></td>
<td>最大似然估计</td>
<td>$\hat{\theta}_{MLE} = \arg\max P(D \mid \theta)$   寻找使观测数据出现概率最大的参数</td>
<td><strong>最通用</strong>。大样本下具有渐近正态性、一致性。对模型假设敏感。</td>
</tr>
<tr>
<td><strong>MM</strong></td>
<td>矩估计法</td>
<td>令样本矩等于总体矩：$E[X^k] = \frac{1}{n}\sum X_i^k$</td>
<td>简单快速，不需要知道分布的具体形式。但在小样本下往往不是有效估计量。</td>
</tr>
<tr>
<td><strong>LSE</strong></td>
<td>最小二乘估计</td>
<td>$\min \sum (y_i - \hat{y}_i)^2$   最小化残差平方和</td>
<td>线性回归。<strong>不需要概率分布假设</strong>（若误差服从正态分布，则等价于 MLE）。</td>
</tr>
<tr>
<td><strong>GMM</strong></td>
<td>广义矩估计</td>
<td>利用过定矩条件（矩条件多于参数），最小化二次型距离</td>
<td><strong>经济计量学常用</strong>。解决了内生性问题，且不需要对误差分布做强假设。</td>
</tr>
<tr>
<td><strong>M-估计</strong></td>
<td>稳健估计</td>
<td>替换平方损失函数为更抗噪的 $\rho$ 函数（如 Huber 损失）</td>
<td><strong>数据有异常值（Outliers）时</strong>。比 MLE 更鲁棒。</td>
</tr>
<tr>
<td><strong>EM</strong></td>
<td>期望极大算法</td>
<td>交替进行 E-step（求期望）和 M-step（极大化似然）</td>
<td><strong>含有隐变量</strong>（Latent variables）的概率模型，如 GMM 聚类、HMM。</td>
</tr>
</tbody></table>
<h2 id="贝叶斯学派"><a href="#贝叶斯学派" class="headerlink" title="贝叶斯学派"></a>贝叶斯学派</h2><h3 id="核心思想-1"><a href="#核心思想-1" class="headerlink" title="核心思想"></a>核心思想</h3><p>贝叶斯派（Bayesian）将概率解释为对事件发生的不确定性的度量，这种不确定性可以是主观的信念。在这一框架下，参数 $ \theta $ 被视为一个随机变量，服从某个先验分布 $ p(\theta) $，这个先验分布反映了我们在看到数据之前对参数的认知。</p>
<h3 id="贝叶斯定理与后验分布"><a href="#贝叶斯定理与后验分布" class="headerlink" title="贝叶斯定理与后验分布"></a>贝叶斯定理与后验分布</h3><p>当我们观测到数据 $ X $ 后，根据贝叶斯定理，我们可以更新对参数的认知，得到<strong>后验分布</strong>（Posterior Distribution）：</p>
<p>$$p(\theta|X) = \frac{p(X|\theta) \cdot p(\theta)}{p(X)} = \frac{p(X|\theta) \cdot p(\theta)}{\int p(X|\theta) \cdot p(\theta) \, d\theta}$$</p>
<p>其中：</p>
<ul>
<li>$ p(X|\theta) $ 是似然函数，与频率派中的定义相同</li>
<li>$ p(\theta) $ 是先验分布，体现了我们对参数的主观先验知识</li>
<li>$ p(X) = \int p(X|\theta)p(\theta)d\theta $ 是边缘似然，也称为证据（Evidence），作为归一化常数确保后验概率之和为1</li>
</ul>
<h3 id="最大后验估计"><a href="#最大后验估计" class="headerlink" title="最大后验估计"></a>最大后验估计</h3><p>虽然贝叶斯派的完整结果是整个后验分布，但在实际应用中有时也需要一个点估计。这时可以采用<strong>最大后验估计</strong>（Maximum A Posteriori, MAP）：</p>
<p>$$\theta_{MAP} = \arg\max_{\theta} p(\theta|X) = \arg\max_{\theta} p(X|\theta) \cdot p(\theta) \tag{4}$$</p>
<p>MAP估计巧妙地结合了似然函数和先验信息。从优化的角度看，先验分布起到了<strong>正则化</strong>的作用：例如，高斯先验对应L2正则化，拉普拉斯先验对应L1正则化。</p>
<h3 id="贝叶斯预测"><a href="#贝叶斯预测" class="headerlink" title="贝叶斯预测"></a>贝叶斯预测</h3><p>贝叶斯方法真正的优势在于其能够进行概率预测。当我们得到后验分布后，对于新样本 $ x_{new} $ 的预测分布可以通过对参数空间进行积分得到：</p>
<p>$$p(x_{new}|X) = \int p(x_{new}|\theta) \cdot p(\theta|X) \, d\theta \tag{5}$$</p>
<p>这个过程被称为<strong>贝叶斯模型平均</strong>（Bayesian Model Averaging）。与频率派只使用单一最优参数不同，贝叶斯方法考虑了所有可能的参数值，并依据后验概率进行加权平均，从而自然地体现了模型的不确定性。</p>
<h3 id="贝叶斯派与机器学习"><a href="#贝叶斯派与机器学习" class="headerlink" title="贝叶斯派与机器学习"></a>贝叶斯派与机器学习</h3><p>贝叶斯派思想催生了**概率图模型（Probabilistic Graphical Models）**这一重要领域，包括：</p>
<ul>
<li><strong>朴素贝叶斯分类器</strong>：最简单的贝叶斯模型，假设特征条件独立</li>
<li><strong>高斯过程</strong>：非参数贝叶斯方法，用于回归和分类</li>
<li><strong>贝叶斯神经网络</strong>：为神经网络权重赋予先验分布</li>
</ul>
<p>贝叶斯方法的优势在于：能够自然地融合先验知识、防止过拟合、提供不确定性估计、适用于小样本学习。但同时也面临挑战：后验分布的计算通常涉及高维积分，难以解析求解，需要借助近似方法如马尔可夫链蒙特卡洛（MCMC）、变分推断等。</p>
<h3 id="贝叶斯学派的参数估计"><a href="#贝叶斯学派的参数估计" class="headerlink" title="贝叶斯学派的参数估计"></a>贝叶斯学派的参数估计</h3><table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>核心思想</strong></th>
<th><strong>输出形式</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>MAP</strong></td>
<td>最大后验估计   $\arg\max P(D \mid \theta) P(\theta)$</td>
<td><strong>点估计</strong>   (单个数值)</td>
<td>相当于 <strong>MLE + 先验</strong>。在线性回归中增加高斯先验即等价于 <strong>L2 正则化 (Ridge)</strong>。</td>
</tr>
<tr>
<td><strong>贝叶斯推断</strong></td>
<td>计算完整的后验分布   $P(\theta \mid D) = \frac{P(D \mid \theta) P(\theta)}{\int P(D \mid \theta) P(\theta) d\theta}$</td>
<td><strong>后验分布</strong></td>
<td>提供不确定性度量（均值、方差）。当先验是<strong>共轭先验</strong>时有解析解。</td>
</tr>
<tr>
<td><strong>MCMC</strong></td>
<td>马尔可夫链蒙特卡洛采样 (如 Gibbs 采样)</td>
<td><strong>采样样本点集</strong></td>
<td>通过随机采样模拟复杂的后验分布。<strong>万能但慢</strong>，适用于高维复杂模型。</td>
</tr>
<tr>
<td><strong>变分推断 (VI)</strong></td>
<td>将推断问题转化为<strong>优化问题</strong>   寻找一个简单分布 $q(\theta)$ 最小化 $KL(q | p$</td>
<td><strong>近似解析分布</strong></td>
<td>牺牲了一定精度换取速度。是大规模深度贝叶斯学习（如 VAE）的核心。</td>
</tr>
</tbody></table>
<h2 id="频率派与贝叶斯派对比"><a href="#频率派与贝叶斯派对比" class="headerlink" title="频率派与贝叶斯派对比"></a>频率派与贝叶斯派对比</h2><p>尽管存在哲学分歧，两大学派在方法论上有着深刻的联系：</p>
<ul>
<li><strong>MLE与MAP的关系</strong>：当先验分布为均匀分布时，MAP估计退化为MLE估计</li>
<li><strong>正则化视角</strong>：MLE + 正则化项 等价于 MAP（特定先验）</li>
<li><strong>大样本一致性</strong>：当样本量趋于无穷时，后验分布会集中在MLE估计附近，贝叶斯估计渐近等价于频率派估计</li>
</ul>
<p>现代机器学习中，两大学派的界限正变得越来越模糊。研究者们开始汲取两者的优势：</p>
<ul>
<li><strong>贝叶斯深度学习</strong>：将贝叶斯思想引入深度神经网络，解决过拟合和不确定性估计问题</li>
<li><strong>集成学习</strong>：结合多个模型的思想与贝叶斯模型平均有异曲同工之妙</li>
<li><strong>概率编程</strong>：提供灵活的框架来表达和求解概率模型</li>
<li><strong>变分自编码器（VAE）</strong>：巧妙结合了深度学习与变分推断</li>
</ul>
<h2 id="应用场景选择"><a href="#应用场景选择" class="headerlink" title="应用场景选择"></a>应用场景选择</h2><p>在实际问题中，选择哪种方法取决于具体需求：</p>
<ul>
<li><strong>数据量巨大</strong>：频率派方法通常计算更高效</li>
<li><strong>小样本或零样本学习</strong>：贝叶斯方法可以利用先验知识</li>
<li><strong>需要不确定性估计</strong>：贝叶斯方法自然提供</li>
<li><strong>模型解释性要求高</strong>：简单频率派模型更易解释</li>
<li><strong>计算资源有限</strong>：频率派方法通常更友好</li>
</ul>
<h1 id="按建模目标划分"><a href="#按建模目标划分" class="headerlink" title="按建模目标划分"></a>按建模目标划分</h1><h2 id="判别式"><a href="#判别式" class="headerlink" title="判别式"></a>判别式</h2><ul>
<li><strong>直接</strong>对后验概率 <code>P(y | x)</code> 进行建模。</li>
<li><strong>关注点</strong>：直接学习决策边界，即不同类别之间的界限。</li>
<li><strong>例子</strong>：逻辑回归、神经网络、支持向量机。</li>
<li><strong>比喻</strong>：学会直接区分狗和猫的图片（只看区别）。</li>
</ul>
<h2 id="生成式"><a href="#生成式" class="headerlink" title="生成式"></a>生成式</h2><ul>
<li><strong>间接</strong>地对<strong>似然 (Likelihood)</strong> <code>P(x | y)</code> 和<strong>先验 (Prior)</strong> <code>P(y)</code> 进行建模。</li>
<li><strong>关注点</strong>：为每个类别单独建模其特征的分布。“生成式”是因为一旦学到了 <code>P(x | y)</code>，就可以为任何类别 <code>y</code> 生成新的样本 <code>x</code>。</li>
<li><strong>步骤</strong>：<ol>
<li>为每个类别 <code>y</code> 假设一个特征分布模型（例如高斯分布）。</li>
<li>从训练数据中估计每个类别分布的参数（如均值、方差）。</li>
<li>利用贝叶斯定理，将学到的 <code>P(x | y)</code> 和 <code>P(y)</code> 转换为最终用于分类的 <code>P(y | x)</code>。</li>
</ol>
</li>
<li><strong>比喻</strong>：分别学习“狗看起来是什么样”和“猫看起来是什么样”的完整模型，然后对于一个新动物，看它更符合哪个模型。</li>
</ul>
<h2 id="判别式与生成式的模型对比"><a href="#判别式与生成式的模型对比" class="headerlink" title="判别式与生成式的模型对比"></a>判别式与生成式的模型对比</h2><p><strong>判别模型</strong> 和 <strong>生成模型</strong> 的根本区别在于它们<strong>解决问题的思路和关注点</strong>不同。</p>
<ul>
<li><p><strong>判别模型</strong> 致力于 <strong>“找到区别”</strong>。</p>
<ul>
<li><strong>思路</strong>：直接学习不同类别数据之间的<strong>决策边界</strong>，而不关心单个类别本身的具体样貌。</li>
<li><strong>目标</strong>：回答“<strong>它更像是猫还是狗？</strong>”</li>
<li><strong>好比</strong>：一个裁判，他不需要会画画，只需要掌握一个关键标准（比如身长）来快速区分两者。</li>
</ul>
</li>
<li><p><strong>生成模型</strong> 致力于 <strong>“理解本质”</strong>。</p>
<ul>
<li><strong>思路</strong>：分别学习每一类数据（如猫、狗）的<strong>整体特征和内部结构</strong>，为每个类别建立一个完整的“概念模型”。</li>
<li><strong>目标</strong>：回答“<strong>猫&#x2F;狗长什么样子？</strong>”</li>
<li><strong>好比</strong>：一个艺术家，他需要透彻地了解猫和狗的骨骼、肌肉、毛发等所有细节，才能把它们画出来。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">特征</th>
<th align="left"><strong>判别模型（Discriminative）</strong></th>
<th align="left"><strong>生成模型（Generative）</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>核心思想</strong></td>
<td align="left">学习类别之间的<strong>边界</strong>，找到“差异”。</td>
<td align="left">学习数据本身的<strong>分布</strong>，理解每一类的“本质”。</td>
</tr>
<tr>
<td align="left"><strong>解决的问题</strong></td>
<td align="left">这是X还是Y</td>
<td align="left">什么是X</td>
</tr>
<tr>
<td align="left"><strong>学习内容</strong></td>
<td align="left">条件概率p(y|x)   （x是数据特征，y是数据标签）</td>
<td align="left">联合概率p(x,y)、分布p(x)（无监督的情况）</td>
</tr>
<tr>
<td align="left"><strong>能力</strong></td>
<td align="left">主要用于<strong>分类和回归</strong>，无法生成新数据。</td>
<td align="left">既可以进行分类，也可以<strong>生成新的数据</strong>（如画一只猫）。</td>
</tr>
<tr>
<td align="left"><strong>类比</strong></td>
<td align="left">只学会一个<strong>投机取巧的判别技巧</strong>（如比身长）。</td>
<td align="left">学完后对猫狗有<strong>直观认知</strong>，能画出它们。</td>
</tr>
<tr>
<td align="left"><strong>常见算法</strong></td>
<td align="left">逻辑回归、支持向量机、决策树、CRF、神经网络</td>
<td align="left">朴素贝叶斯、高斯混合、隐马尔可夫模型、VAF、生成对抗网络</td>
</tr>
</tbody></table>
<p><strong>判别模型因为只专注于区分，因此不具备生成能力；而生成模型因为学会了数据的“本质”，所以具备生成新数据的能力。</strong></p>
<p>ChatGPT、Midjourney这类能创作内容（生成文本、图像）的模型，其核心都是<strong>生成模型</strong>。而许多用于图像分类、垃圾邮件过滤等任务的模型，则更多是<strong>判别模型</strong>。</p>
<h2 id="生成与判别式模型的选择"><a href="#生成与判别式模型的选择" class="headerlink" title="生成与判别式模型的选择"></a>生成与判别式模型的选择</h2><ul>
<li>当数据量较少或对数据分布有较强先验知识时，<strong>生成学习方法</strong>可能更有效。<ul>
<li>适用于数据生成、缺失值处理；</li>
<li>在小样本下可能比判别模型（如逻辑回归）更鲁棒。</li>
</ul>
</li>
<li>当数据量充足且计算资源有限时，判别学习方法可能更合适。</li>
</ul>
<h1 id="按学习目标划分"><a href="#按学习目标划分" class="headerlink" title="按学习目标划分"></a>按学习目标划分</h1><h2 id="回归（Regression）"><a href="#回归（Regression）" class="headerlink" title="回归（Regression）"></a>回归（Regression）</h2><ul>
<li>回归旨在建立输入特征与连续型输出变量之间的映射关系，回归任务的目标是预测一个<strong>连续的数值输出</strong> $y \in \mathbb{R}$，</li>
<li><strong>核心思想</strong>：找到一条曲线&#x2F;超平面，使预测值 $\hat{y}$ 尽可能接近真实值 $y$，最小化预测误差: $ \min_\theta \sum_{i=1}^N (y_i - \hat{y}_i)^2 $</li>
<li>应用场景：预测房价、售额预测、股票价格等。</li>
</ul>
<p>常见的回归算法:</p>
<ul>
<li><strong>线性回归</strong>：最简单的回归模型，假设输入与输出呈线性关系</li>
<li><strong>岭回归&#x2F;Lasso</strong>：在线性回归基础上加入L2&#x2F;L1正则化，防止过拟合</li>
<li><strong>决策树回归</strong>：通过树结构分段拟合数据</li>
<li><strong>随机森林回归</strong>：集成多棵决策树，降低方差</li>
<li><strong>梯度提升回归</strong>（GBDT、XGBoost）：通过迭代优化残差</li>
<li><strong>支持向量回归（SVR）</strong>：利用核方法处理非线性关系</li>
<li><strong>神经网络</strong>：能够拟合任意复杂的非线性函数</li>
</ul>
<h2 id="分类（Classification）"><a href="#分类（Classification）" class="headerlink" title="分类（Classification）"></a>分类（Classification）</h2><ul>
<li>目标是预测离散的类别标签（Y）。</li>
<li>例如：判断邮件是否为垃圾邮件（类别：垃圾邮件&#x2F;非垃圾邮件）、识别图像中的物体类别（类别：猫&#x2F;狗&#x2F;车等）。</li>
</ul>
<p>预测离散类别标签。根据类别数量可分为：</p>
<ul>
<li><strong>二分类</strong>： 只有两个类别，例如垃圾邮件分类。</li>
<li><strong>多分类</strong>：包含多个类别，例如手写数字识别（0-9）。</li>
<li><strong>多标签分类</strong>：一个样本可能属于多个类别</li>
</ul>
<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>给定输入特征向量 $\mathbf{x} \in \mathbb{R}^d$，分类问题的目标是预测其所属的<strong>离散类别标签</strong> $y \in \{1, 2, ..., K\}$。</p>
<p>从概率视角看，我们需要计算<strong>后验概率</strong>（posterior probability）：<br>$$<br>P(y &#x3D; k \mid \mathbf{x}), \quad k &#x3D; 1,2,…,K<br>$$</p>
<p>所有分类模型最终都采用<strong>最大后验决策规则</strong>（MAP decision rule）进行预测：<br>$$<br>\hat{y} &#x3D; \arg\max_{k} P(y &#x3D; k \mid \mathbf{x})<br>$$<br>即选择使后验概率最大的类别作为预测结果。</p>
<h3 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h3><h4 id="判别式学习建模（Discriminative）"><a href="#判别式学习建模（Discriminative）" class="headerlink" title="判别式学习建模（Discriminative）"></a>判别式学习建模（Discriminative）</h4><ul>
<li><strong>直接建模</strong> $P(y|\mathbf{x})$</li>
<li>关注决策边界，不关心数据本身的分布</li>
</ul>
<h4 id="生成式学习建模（Generative）"><a href="#生成式学习建模（Generative）" class="headerlink" title="生成式学习建模（Generative）"></a>生成式学习建模（Generative）</h4><ul>
<li><strong>间接建模</strong>：先学习联合分布 $ P(\mathbf{x}, y) = P(y)P(\mathbf{x}|y) $</li>
<li>通过贝叶斯定理计算后验：$ P(y|\mathbf{x}) = \frac{P(y)P(\mathbf{x}|y)}{\sum_{k=1}^K P(y=k)P(\mathbf{x}|y=k)} $</li>
</ul>
<h3 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h3><p>无论采用判别式还是生成式方法，模型都包含需要从数据中学习的参数 $\theta$。参数估计主要有两种方法：</p>
<h4 id="频率派的最大似然估计（MLE）"><a href="#频率派的最大似然估计（MLE）" class="headerlink" title="频率派的最大似然估计（MLE）"></a>频率派的<strong>最大似然估计（MLE）</strong></h4><p>​		将参数视为确定的未知常量，寻找使训练数据似然函数最大化的参数值：<br>$$<br>\theta_{MLE} &#x3D; \arg\max_\theta \prod_{i&#x3D;1}^N P(y_i|\mathbf{x}_i, \theta)<br>$$<br>​		等价于最小化经验风险。</p>
<h4 id="贝叶斯派的最大后验估计（MAP）"><a href="#贝叶斯派的最大后验估计（MAP）" class="headerlink" title="贝叶斯派的最大后验估计（MAP）"></a>贝叶斯派的<strong>最大后验估计（MAP）</strong></h4><p>​		将参数视为随机变量，在MLE的基础上引入了参数的先验分布$p(\theta)$，通过贝叶斯定理求使<strong>后验概率</strong>最大的参数值：<br>$$<br>\theta_{MAP} &#x3D; \arg\max_\theta \prod_{i&#x3D;1}^N P(y_i|\mathbf{x}_i, \theta) \cdot p(\theta)<br>$$</p>
<ul>
<li><strong>正则化效应</strong>：先验分布 $p(\theta)$ 等价于对参数施加约束，防止过拟合<ul>
<li>高斯先验 $p(\theta) \sim \mathcal{N}(0, \sigma^2)$ ↔ L2 正则化</li>
<li>拉普拉斯先验 $p(\theta) \sim \text{Laplace}(0, b)$ ↔ L1 正则化</li>
</ul>
</li>
<li>在数据稀缺时，先验知识可提供更稳健的估计</li>
<li>当先验为均匀分布时，MAP 退化为 MLE</li>
</ul>
<h3 id="完整流程"><a href="#完整流程" class="headerlink" title="完整流程"></a>完整流程</h3><ol>
<li><strong>训练阶段</strong>：使用MLE或MAP估计模型参数 $\hat{\theta}$</li>
<li><strong>预测阶段</strong>：对于新样本 $\mathbf{x}_{new}$，计算后验概率：$P(y=k|\mathbf{x}_{new}, \hat{\theta})$</li>
<li><strong>决策阶段</strong>：应用最大后验决策规则：$\hat{y} = \arg\max_k P(y=k|\mathbf{x}_{new}, \hat{\theta})$</li>
</ol>
<h2 id="聚类（Clustering）"><a href="#聚类（Clustering）" class="headerlink" title="聚类（Clustering）"></a>聚类（Clustering）</h2><p>聚类是一种<strong>无监督学习</strong>任务，目标是将未标注的样本划分为若干个<strong>簇</strong>（cluster），使得同一簇内的样本尽可能相似，不同簇间的样本尽可能不同。</p>
<p>给定数据集 $\{\mathbf{x}_1, \mathbf{x}_2, ..., \mathbf{x}_N\}$，聚类算法旨在找到一种划分 $C = \{C_1, C_2, ..., C_K\}$，使得：</p>
<ul>
<li>簇内相似度最大化：$\max \sum_{k=1}^K \sum_{\mathbf{x}_i \in C_k} \text{sim}(\mathbf{x}_i, \mu_k)$</li>
<li>簇间相似度最小化：$\min \sum_{k \lt j} \text{sim}(\mu_k, \mu_j)$，其中 $\mu_k$ 是第 $k$ 个簇的中心（或代表点），$\text{sim}(\cdot)$ 是相似度度量。</li>
</ul>
<h2 id="降维（Dimensionality-Reduction）"><a href="#降维（Dimensionality-Reduction）" class="headerlink" title="降维（Dimensionality Reduction）"></a>降维（Dimensionality Reduction）</h2><p>降维是将高维数据映射到低维空间的过程，同时尽可能保留原始数据的重要结构信息。它是<strong>无监督学习</strong>的重要分支，也是数据预处理的关键步骤。</p>
<p>给定高维数据 $\{\mathbf{x}_i \in \mathbb{R}^D\}_{i=1}^N$，降维算法寻找映射 $f: \mathbb{R}^D \rightarrow \mathbb{R}^d$，其中 $d \ll D$，使得：<br>$$\mathbf{z}_i = f(\mathbf{x}_i) \in \mathbb{R}^d$$<br>且 $\{\mathbf{z}_i\}$ 尽可能保留 $\{\mathbf{x}_i\}$ 的重要结构信息。</p>
<p>需要降维的场景:</p>
<ul>
<li><strong>维度灾难（Curse of Dimensionality）</strong>：随着维度增加，数据变得稀疏，距离度量失效，模型复杂度指数级增长</li>
<li><strong>可视化需求</strong>：人类只能理解2D或3D空间，降维使高维数据可视化成为可能</li>
<li><strong>计算效率</strong>：减少特征数量，降低模型训练和预测的时间复杂度</li>
<li><strong>去噪</strong>：丢弃不重要的维度，保留主要信号</li>
<li><strong>特征提取</strong>：从原始特征中构造更有代表性的新特征</li>
</ul>
<h2 id="排序（Ranking）"><a href="#排序（Ranking）" class="headerlink" title="排序（Ranking）"></a>排序（Ranking）</h2><p>排序任务的目标是学习一个<strong>排序函数</strong>，能够根据输入特征对项目集合进行排序，使得<strong>相关性高</strong>的项目排在前面。排序问题是信息检索和推荐系统的核心。</p>
<p>排序的应用场景:</p>
<ul>
<li><strong>搜索引擎</strong>：根据用户查询对网页进行排序</li>
<li><strong>推荐系统</strong>：为用户推荐最感兴趣的商品、视频、音乐</li>
<li><strong>问答系统</strong>：对候选答案按相关性排序</li>
<li><strong>广告点击率预测</strong>：排序广告以提高点击率</li>
<li><strong>社交媒体</strong>：排序信息流中的帖子</li>
</ul>
<h1 id="常见模型一览表"><a href="#常见模型一览表" class="headerlink" title="常见模型一览表"></a>常见模型一览表</h1><table>
<thead>
<tr>
<th><strong>算法模型</strong></th>
<th><strong>频率派</strong></th>
<th><strong>贝叶斯派</strong></th>
<th><strong>判别式</strong></th>
<th><strong>生成式</strong></th>
<th><strong>参数估计&#x2F;核心准则</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>线性回归</strong></td>
<td>是</td>
<td>是 (贝叶斯线性回归)</td>
<td>是</td>
<td>否</td>
<td>最小二乘 (OLS) &#x2F; MLE</td>
</tr>
<tr>
<td><strong>逻辑回归</strong></td>
<td>是</td>
<td>是 (拉普拉斯近似等)</td>
<td>是</td>
<td>否</td>
<td>极大似然估计 (MLE)</td>
</tr>
<tr>
<td><strong>决策树&#x2F;随机森林&#x2F;提升树</strong></td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>信息增益 &#x2F; 基尼系数 &#x2F; MSE</td>
</tr>
<tr>
<td><strong>SVM</strong></td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>合页损失 + 正则化 (对偶优化)</td>
</tr>
<tr>
<td><strong>PCA (主成分分析)</strong></td>
<td>是</td>
<td>是 (Probabilistic PCA)</td>
<td>不适用</td>
<td>是 (概率视角下)</td>
<td>方差最大化 &#x2F; 投影误差最小化</td>
</tr>
<tr>
<td><strong>LDA (线性判别分析)</strong></td>
<td>是</td>
<td>否</td>
<td>否</td>
<td><strong>是</strong></td>
<td>Fisher 准则 &#x2F; 类内类间散度</td>
</tr>
<tr>
<td><strong>高斯判别分析 (GDA)</strong></td>
<td>是</td>
<td>是</td>
<td>否</td>
<td><strong>是</strong></td>
<td>联合概率 $P(x,y)$ 建模</td>
</tr>
<tr>
<td><strong>高斯过程 (GP)</strong></td>
<td>否</td>
<td><strong>是</strong></td>
<td>是</td>
<td>否</td>
<td>核函数 + 边际似然最大化</td>
</tr>
<tr>
<td><strong>高斯混合模型 (GMM)</strong></td>
<td>是</td>
<td>是 (贝叶斯 GMM)</td>
<td>否</td>
<td><strong>是</strong></td>
<td><strong>EM 算法</strong></td>
</tr>
<tr>
<td><strong>朴素贝叶斯</strong></td>
<td>是</td>
<td><strong>是</strong></td>
<td>否</td>
<td><strong>是</strong></td>
<td>MAP (带平滑) &#x2F; MLE</td>
</tr>
<tr>
<td><strong>贝叶斯网络</strong></td>
<td>否</td>
<td><strong>是</strong></td>
<td>否</td>
<td><strong>是</strong></td>
<td>结构学习 + 条件概率表</td>
</tr>
<tr>
<td><strong>隐马尔可夫 (HMM)</strong></td>
<td>是</td>
<td>是 (变分推断)</td>
<td>否</td>
<td><strong>是</strong></td>
<td>EM 算法</td>
</tr>
<tr>
<td><strong>条件随机场 (CRF)</strong></td>
<td>是</td>
<td>否</td>
<td><strong>是</strong></td>
<td>否</td>
<td>极大似然 (梯度上升)</td>
</tr>
<tr>
<td><strong>感知机</strong></td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>随机梯度下降 (SGD)</td>
</tr>
<tr>
<td><strong>深度神经网络 (DNN)</strong></td>
<td>是</td>
<td>是 (BNN)</td>
<td>是</td>
<td>视模型而定</td>
<td>反向传播 (BP) + 优化器</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>频率学派</tag>
        <tag>贝叶斯学派</tag>
        <tag>判别式模型</tag>
        <tag>生成式模型</tag>
        <tag>回归</tag>
        <tag>分类</tag>
      </tags>
  </entry>
</search>
